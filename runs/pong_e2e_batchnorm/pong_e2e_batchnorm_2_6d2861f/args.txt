run.py train_policy_with_preferences PongNoFrameskip-v4 --headless --n_envs 16 --million_timesteps 20 --reward_predictor_ckpt_interval 1000 --policy_ckpt_interval 5000 --batchnorm --run_name pong_e2e_batchnorm_2 --seed 2
Namespace(batchnorm=True, debug=False, dropout=0.0, ent_coef=0.01, env='PongNoFrameskip-v4', headless=True, load_policy_ckpt_dir=None, load_prefs_dir=None, load_reward_predictor_ckpt=None, log_dir=None, log_interval=100, lr=0.0007, lr_zero_million_timesteps=None, max_prefs=3000, max_segs=1000, million_timesteps=20.0, mode='train_policy_with_preferences', n_envs=16, n_initial_epochs=200, n_initial_prefs=500, network='cnn', policy_ckpt_interval=5000, render_episodes=False, reward_predictor_ckpt_interval=1000, reward_predictor_learning_rate=0.0002, run_name='pong_e2e_batchnorm_2', seed=2, test_mode=False)